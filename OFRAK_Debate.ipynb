{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YkXAdTsYwHg"
      },
      "source": [
        "# OFRAK Debate\n",
        "Simulate a Donald Trump and Kamala Harris debate with CEO Ang Cui as moderator in OFRAK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZKbkbSVmTFB"
      },
      "source": [
        "**First**, Why.\n",
        "OFRAK, the Open Firmware Reverse Analysis Konsole, is a framework that lets you do very fancy firmware analysis, very brave assured micro firmware patching, in a simple interface that lets you roll in all your favorite tools into an eloquent, agile ninja workflow. This is not a tool to run a LLM-driven fevor dream of a presidential debate.\n",
        "\n",
        "**Second**, Huh?\n",
        "Yes. OFRAK is kick ass for firmware stuff. But can you do fancy complicated things that isn't in the old boring process of unpack, analyze, modify, repack? Let's find out.\n",
        "\n",
        "**Third**, How?\n",
        "Look below. You can do intersting scaled things if you know how to work with FirmwareObject (<-replace with what we call it now), our new dumb simple LLM analyzer interface, and a little healthy sense of amazifunventure.\n",
        "\n",
        "**Fourth**, Who the f#@(@#! is this clown moderator?\n",
        "IT is a doctor, anonymous user. And that's Doctor Clown to you, bachelor.\n",
        "\n",
        "Install OFRAK, Pull OFRAK project, put in your own API tokens for the LLM stuff, laugh or sigh. up to you -)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwrWEE0wiqiD"
      },
      "source": [
        "## INSTALL\n",
        "Clone the ofrak_debates repo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFwTNKush9qB"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/redballoonsecurity/ofrak_debates.git\n",
        "!mv ofrak_debates/* .\n",
        "!rm -rf ofrak_debates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoHIxJtqW4xO"
      },
      "source": [
        "OFRAK's LLM features are on a WIP dev branch. Let's pull that version here and get it installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs3iP6I7YGi2"
      },
      "outputs": [],
      "source": [
        "!git clone -b feature/llm-analyzer https://github.com/rbs-jacob/ofrak.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBZGMbZNcx2C"
      },
      "outputs": [],
      "source": [
        "!pushd ofrak/ofrak_type && make install && popd\n",
        "!pushd ofrak/ofrak_io && make install && popd\n",
        "!pushd ofrak/ofrak_patch_maker && make install && popd\n",
        "!pushd ofrak/frontend && npm install && npm run build && popd\n",
        "!pushd ofrak/ofrak_core && cp -r ../frontend/dist ofrak/gui/public && make install && pushd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0N6V2CRXIyw"
      },
      "source": [
        "If everything went well, we should see some LLM analyzers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mCfA5Z0pc-0j"
      },
      "outputs": [],
      "source": [
        "!ofrak list | grep Llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_bLC_VggOV5"
      },
      "source": [
        "Accept the OFRAK community license:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHTqZ23qgEzI"
      },
      "outputs": [],
      "source": [
        "!ofrak license --community --i-agree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz-PFUY8mbEs"
      },
      "source": [
        "## Let's run it.\n",
        "\n",
        "Set the url to your F5-TTS gradio UI and OLLAMA instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CWLrce2PmZUv"
      },
      "outputs": [],
      "source": [
        "TTS_URL = \"http://198.145.104.49:7860\"\n",
        "OLLAMA_URL = \"http://198.145.104.49:11434/api/chat\"\n",
        "OLLAMA_MODEL = \"llama3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VFqH35tcj0Qw"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "from ofrak import OFRAK\n",
        "from ofrak.core import *\n",
        "from ofrak.core.llm import *\n",
        "\n",
        "from debate_components import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff9SeAAdak8N"
      },
      "outputs": [],
      "source": [
        "o = OFRAK()\n",
        "import debate_components\n",
        "\n",
        "o.discover(debate_components)\n",
        "ofrak_context = await o.create_ofrak_context()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6hEg8OkYVC9"
      },
      "source": [
        "Lets create our OFRAK resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I0ThLwDcj5YE"
      },
      "outputs": [],
      "source": [
        "dr_ang_cui_resource = await ofrak_context.create_root_resource_from_file(\n",
        "    \"questions.txt\",\n",
        ")\n",
        "dr_ang_cui_resource.add_view(Person(\"Dr. Ang Cui\", \"voices/Ang_Cui.wav\"))\n",
        "await dr_ang_cui_resource.save()\n",
        "\n",
        "djt_resource = await ofrak_context.create_root_resource(\n",
        "    name=\"Donald Trump\", data=b\"\", tags=(GenericBinary, Person)\n",
        ")\n",
        "djt_resource.add_view(Person(\"Donald Trump\", \"voices/Donald_Trump.wav\"))\n",
        "await djt_resource.save()\n",
        "\n",
        "kh_resource = await ofrak_context.create_root_resource(\n",
        "    name=\"Kamala Harris\",\n",
        "    data=b\"\",\n",
        "    tags=(GenericBinary, Person),\n",
        ")\n",
        "kh_resource.add_view(Person(\"Kamala Harris\", \"voices/Kamala_Harris.wav\"))\n",
        "await kh_resource.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtRMMz9DYfM-"
      },
      "source": [
        "Get our questions ready..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLAeFD1QYj8U"
      },
      "outputs": [],
      "source": [
        "debate_questions = await dr_ang_cui_resource.get_data()\n",
        "print(debate_questions.decode())\n",
        "questions = enumerate(debate_questions.decode().splitlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "73hvq9-jYqhO"
      },
      "outputs": [],
      "source": [
        "async def ask_question(\n",
        "    question: str, moderator: Resource, candidate_one: Resource, candidate_two: Resource\n",
        "):\n",
        "    i, question = question\n",
        "    print(f\"[+] Asking question {i + 1}\")\n",
        "    # Dr. Ang Cui asks the question\n",
        "    await dr_ang_cui_resource.run(\n",
        "        TTSAnalyzer,\n",
        "        TTSAnalyzerConfig(start_line=i, num_lines=i + 1, client_url=TTS_URL),\n",
        "    )\n",
        "    IPython.display.display(\n",
        "        IPython.display.Audio(\n",
        "            dr_ang_cui_resource.get_attributes(WavFile).wav, autoplay=True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Donald Trump answers the question\n",
        "    await djt_resource.run(\n",
        "        AnswerQuestionModifier, AnswerQuestionConfig(question, ollama_url = OLLAMA_URL,ollama_model=OLLAMA_MODEL, tts_client_url=TTS_URL)\n",
        "    )\n",
        "    IPython.display.display(\n",
        "        IPython.display.Audio(djt_resource.get_attributes(WavFile).wav, autoplay=True)\n",
        "    )\n",
        "\n",
        "    # Kamala Harris answers the question\n",
        "    await kh_resource.run(\n",
        "        AnswerQuestionModifier, AnswerQuestionConfig(question, ollama_url = OLLAMA_URL,ollama_model=OLLAMA_MODEL, tts_client_url=TTS_URL)\n",
        "    )\n",
        "    IPython.display.display(\n",
        "        IPython.display.Audio(kh_resource.get_attributes(WavFile).wav, autoplay=True)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZabm6y6Y6bw"
      },
      "source": [
        "Now we should be able to run this function as many times as we have questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8H3rl-cZEUD"
      },
      "outputs": [],
      "source": [
        "await ask_question(next(questions), dr_ang_cui_resource, djt_resource, kh_resource)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
